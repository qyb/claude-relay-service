# Claude Relay Service (Antigravity Edition)

[![GitHub](https://img.shields.io/badge/GitHub-dadongwo-181717?logo=github)](https://github.com/dadongwo)
[![Repo](https://img.shields.io/badge/Repo-claude--relay--service-blue?logo=github)](https://github.com/dadongwo/claude-relay-service)

Maintained fork by **dadongwo**.

This fork focuses on:
- Native compatibility for `claude` (Claude Code CLI)
- Antigravity OAuth integration + path-based routing
- Better stability for streaming (SSE) workloads
- OpenAI format compatibility for third-party clients
- Optional request/response dumps for debugging

---

## Highlights

- **Claude Code protocol compatibility**: `thoughtSignature` fallback + cache, tool_result passthrough, and message ordering fixes.
- **Antigravity OAuth**: account type `gemini-antigravity` with permission checks.
- **Path-based routing (Anthropic Messages API)**:
  - `/api` -> Claude account pool (default)
  - `/antigravity/api` -> Antigravity OAuth account pool
  - `/gemini-cli/api` -> Gemini OAuth account pool
- **Stability**:
  - Zombie stream watchdog (disconnect after 45s without valid data)
  - Auto retry + account switching for Antigravity `429 Resource Exhausted` (Quota/RateLimit/Capacity distinguished)
  - **Model-level Smart Cooling**: Specific cooling timers for Claude/Opus/Flash to prevent account-wide lockouts
    <br/><img src="assets/image.png" width="400" alt="Model-level Smart Cooling" />
  - **Risk Control Alignment**: Auto-injected `requestType: 'agent'` and optimized system prompts
  - **OpenCode & Oh My OpenCode Support**: Native support for OpenCode configurations and plugins under Antigravity accounts.
- **Observability**: JSONL dumps for request/response/tools/upstream (with size limit + rotation)
- **Streaming Resilience (2026-01)**:
  - Three-level fallback recovery for missing `finishReason`
  - Smart rate-limit parsing (`RetryInfo`/`quotaResetDelay`)
  - Non-stream to stream adapter with 10-min abort timeout
- **MCP Tool Compatibility (2026-01)**:
  - Enhanced `browser_*` tool stability
  - Tool output semantic compression engine
  - Tool input normalization for non-standard args
- **OpenAI Format Compatibility**:
  - `/openai/gemini/v1/chat/completions` -> Gemini/Antigravity pool
  - `/openai/claude/v1/chat/completions` -> Claude pool
  - Automatic format conversion (messages ‚Üî contents)
  - Streaming and non-streaming support
 
 ### üöÄ Engineering Excellence (Hidden Gems)
 
 Under the hood, this logical layer includes sophisticated optimizations for production readiness:
 
 - **üß† Smart Thinking Normalization**: Automatically detects upstream model metadata. When a user's `thinkingBudget` exceeds the model's `maxOutputTokens`, the system applies **Smart Budget Clamping** to prevent upstream rejection (HTTP 400), minimizing manual configuration errors.
 - **üö¶ Intelligent Route Prioritization**: For specific models (like Claude), the system is aware of Antigravity environment differences. It prioritizes `Prod` endpoints over `Sandbox` to avoid known tool-use instability in sandbox environments, ensuring High Availability for critical agentic workflows.
 - **üõ°Ô∏è Strict Schema Enforcement**: Addressing Gemini's strict JSON Schema validation, the built-in cleaning engine automatically removes unsupported keywords (e.g., `$schema`) and upgrades all Function Calling modes to `VALIDATED` (Strict Mode), fundamentally eliminating parameter hallucinations.
 - **üïµÔ∏è Deep Error Detective**: Beyond simple status codes, a three-layer inspector extracts precise backoff times: it prioritizes structured `RetryInfo.retryDelay`, falls back to `QuotaResetDelay`, and finally parses text patterns. This ensures that rate-limit handling is "surgically precise" rather than blindly exponential.


---

## Quick Start

### Requirements
- Node.js 18+ (or Docker)
- Redis 6+/7+

### Docker Compose (recommended)

```bash
cp .env.example .env
cp config/config.example.js config/config.js

# Edit .env at least:
# JWT_SECRET=... (random string)
# ENCRYPTION_KEY=... (32-char random string)

docker-compose up -d
```

### Node (no Docker)

```bash
npm install
cp .env.example .env
cp config/config.example.js config/config.js
npm run setup
npm run service:start:daemon
```

### Admin UI

- URL: `http://<host>:3000/web`
- Initial credentials: generated by `npm run setup` and saved to `data/init.json` (Docker users can also inspect container logs).

---

## Using with Claude Code (CLI)

### Antigravity pool (recommended)

```bash
export ANTHROPIC_BASE_URL="http://<host>:3000/antigravity/api/"
export ANTHROPIC_AUTH_TOKEN="cr_xxxxxxxxxxxx"
export ANTHROPIC_MODEL="claude-opus-4-5"
claude
```

### Gemini pool

```bash
export ANTHROPIC_BASE_URL="http://<host>:3000/gemini-cli/api/"
export ANTHROPIC_AUTH_TOKEN="cr_xxxxxxxxxxxx"
export ANTHROPIC_MODEL="gemini-2.5-pro"
claude
```

### Standard Claude pool

```bash
export ANTHROPIC_BASE_URL="http://<host>:3000/api/"
export ANTHROPIC_AUTH_TOKEN="cr_xxxxxxxxxxxx"
claude
```

---

### 4. üîå OpenCode Integration
 
 Configure `provider` in `~/.config/opencode/opencode.json`:
 
 ```json
 // antigravity config example
 "antigravity": {
   "npm": "@ai-sdk/anthropic",
   "name": "Antigravity",
   "options": {
     "baseURL": "http://localhost:3000/antigravity/api/v1",
     "apiKey": "cr_XXXXXXXXX"
   },
   "models": {
     "claude-opus-4-5-thinking": {
       "name": "Claude Opus 4.5 Thinking",
       "thinking": true,
       "limit": {
         "context": 200000,
         "output": 8192
       },
       "modalities": {
         "input": ["text", "image"],
         "output": ["text"]
       }
     },
     "claude-sonnet-4-5-thinking": {
       "name": "Claude Sonnet 4.5 Thinking",
       "thinking": true,
       "limit": {
         "context": 200000,
         "output": 8192
       },
       "modalities": {
         "input": ["text", "image"],
         "output": ["text"]
       }
     },
     "gemini-3-flash-preview": {
       "name": "Gemini 3 Flash Preview",
       "attachment": true,
       "limit": {
         "context": 1000000,
         "output": 8192
       },
       "modalities": {
         "input": ["text", "image", "pdf"],
         "output": ["text"]
       }
     },
     "gemini-3-pro-preview": {
       "name": "Gemini 3 Pro Preview",
       "thinking": true,
       "attachment": true,
       "limit": {
         "context": 1000000,
         "output": 8192
       },
       "modalities": {
         "input": ["text", "image", "pdf"],
         "output": ["text"]
       }
     }
   }
 },
 
 // codex cli custom account example
 "openai-custom": {
   "npm": "@ai-sdk/openai",
   "name": "OpenAI Custom",
   "options": {
     "baseURL": "http://localhost:3200/openai",
     "apiKey": "cr_xxxxxxxxxxxxxxxx"
   },
   "models": {
     "gpt-5.2": {
       "name": "GPT 5.2 (Custom)",
       "limit": {
         "context": 272000,
         "output": 128000
       },
       "modalities": {
         "input": ["text", "image"],
         "output": ["text"]
       },
       "variants": {
         "none": { "reasoningEffort": "none", "reasoningSummary": "auto", "textVerbosity": "medium" },
         "low": { "reasoningEffort": "low", "reasoningSummary": "auto", "textVerbosity": "medium" },
         "medium": { "reasoningEffort": "medium", "reasoningSummary": "auto", "textVerbosity": "medium" },
         "high": { "reasoningEffort": "high", "reasoningSummary": "detailed", "textVerbosity": "medium" },
         "xhigh": { "reasoningEffort": "xhigh", "reasoningSummary": "detailed", "textVerbosity": "medium" }
       }
     },
     "gpt-5.2-codex": {
       "name": "GPT 5.2 Codex (Custom)",
       "limit": {
         "context": 272000,
         "output": 128000
       },
       "modalities": {
         "input": ["text", "image"],
         "output": ["text"]
       },
       "variants": {
         "low": { "reasoningEffort": "low", "reasoningSummary": "auto", "textVerbosity": "medium" },
         "medium": { "reasoningEffort": "medium", "reasoningSummary": "auto", "textVerbosity": "medium" },
         "high": { "reasoningEffort": "high", "reasoningSummary": "detailed", "textVerbosity": "medium" },
         "xhigh": { "reasoningEffort": "xhigh", "reasoningSummary": "detailed", "textVerbosity": "medium" }
       }
     },
     "gpt-5.1-codex-max": {
       "name": "GPT 5.1 Codex Max (Custom)",
       "limit": {
         "context": 272000,
         "output": 128000
       },
       "modalities": {
         "input": ["text", "image"],
         "output": ["text"]
       },
       "variants": {
         "low": { "reasoningEffort": "low", "reasoningSummary": "detailed", "textVerbosity": "medium" },
         "medium": { "reasoningEffort": "medium", "reasoningSummary": "detailed", "textVerbosity": "medium" },
         "high": { "reasoningEffort": "high", "reasoningSummary": "detailed", "textVerbosity": "medium" },
         "xhigh": { "reasoningEffort": "xhigh", "reasoningSummary": "detailed", "textVerbosity": "medium" }
       }
     }
   }
 }
 ```
 
 #### `oh-my-opencode.json` example:
 
 ```json
 {
   "$schema": "XXXXXXXXX",
   "google_auth": false,
   "agents": {
     "sisyphus": {
       "model": "antigravity/claude-opus-4-5-thinking"
     },
     "oracle": {
       "model": "openai-custom/gpt-5.2"
     },
     "librarian": {
       "model": "opencode/glm-4.7-free"
     },
     "explore": {
       "model": "antigravity/gemini-3-flash-preview"
     },
     "frontend-ui-ux-engineer": {
       "model": "antigravity/gemini-3-pro-preview"
     },
     "document-writer": {
       "model": "antigravity/gemini-3-flash-preview"
     },
     "multimodal-looker": {
       "model": "antigravity/gemini-3-flash-preview"
     }
   }
 }
 ```
 
 ---
 
 ## Using with OpenAI-Compatible Clients

Works with any OpenAI-compatible client (ChatBox, LobeChat, custom apps, etc.)

### Gemini/Antigravity backend

```
Base URL: http://<host>:3000/openai/gemini/v1
API Key: cr_xxxxxxxxxxxx
Model: gemini-2.5-pro or claude-opus-4-5 (Antigravity)
```

### Claude backend

```
Base URL: http://<host>:3000/openai/claude/v1
API Key: cr_xxxxxxxxxxxx
Model: claude-3-5-sonnet
```

---

## Antigravity Quota & Models

- Quota display: in Admin UI -> Accounts -> `gemini-antigravity` -> click **Test/Refresh**.
  > **Note**: Shows **Cooling Down** timer if a specific model group is currently rate-limited.
- Dynamic models list:
  - Anthropic/Claude Code routing: `GET /antigravity/api/v1/models` (proxies Antigravity `fetchAvailableModels`)
  - OpenAI-compatible routing: `GET /openai/gemini/models` (or `GET /openai/gemini/v1/models`)

---

## Debug Dumps (optional)

See `.env.example` for the full list. Common toggles:

- `ANTHROPIC_DEBUG_REQUEST_DUMP=true`
- `ANTHROPIC_DEBUG_RESPONSE_DUMP=true`
- `ANTIGRAVITY_DEBUG_UPSTREAM_REQUEST_DUMP=true`
- `ANTIGRAVITY_DEBUG_UPSTREAM_RESPONSE_DUMP=true`
- `DUMP_MAX_FILE_SIZE_BYTES=10485760`

---

## License

This project is licensed under the [MIT License](LICENSE).
